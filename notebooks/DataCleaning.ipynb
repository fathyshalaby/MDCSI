{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install argilla datasets scikit-learn cleanlab -qqq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argilla as rg\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace api_url with the url to your HF Spaces URL if using Spaces\n",
    "# Replace api_key if you configured a custom API key\n",
    "rg.init(\n",
    "    api_url=\"\",\n",
    "    api_key=\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset,DatasetDict,Dataset\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "from argilla.labeling.text_classification import find_label_errors\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_excel(\"../../../../nfs/aishare/Data/Intent/raw/Label-Arbeiten/Tina-Teil-1-kürzen.xlsx\")\n",
    "data.drop(columns=[\"NEU?\",\"demand_text\"], inplace=True)\n",
    "data.rename(columns={\"new_demand_text\":\"label\"}, inplace=True)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove labels with less than 10 samples\n",
    "data = data.groupby(\"label\").filter(lambda x: len(x) > 10)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"label\"] = data[\"label\"].str.lower()\n",
    "data[\"label\"] = data[\"label\"].str.replace(\"?\", \"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_labels = data[\"label\"].unique()\n",
    "label_count = data[\"label\"].value_counts()\n",
    "print(\"Unique labels: \", unique_labels)\n",
    "print(\"Label count: \", label_count)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove labels with less than 10 samples\n",
    "data = data[data[\"label\"].isin(label_count[label_count>1].index)]\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#rename label to label_name and make label be the id for the label\n",
    "data.rename(columns={\"label\":\"label_name\"}, inplace=True)\n",
    "label2id = {label:idx for idx,label in enumerate(unique_labels)}\n",
    "data[\"label\"] = data[\"label_name\"].apply(lambda x: label2id[x])\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fix the data to be correctly showing german umlauts\n",
    "data[\"text\"] = data[\"text\"].str.replace(\"Ã¼\",\"ü\")\n",
    "data[\"text\"] = data[\"text\"].str.replace(\"Ã¤\",\"ä\")\n",
    "data[\"text\"] = data[\"text\"].str.replace(\"Ã¶\",\"ö\")\n",
    "data[\"text\"] = data[\"text\"].str.replace(\"ÃŸ\",\"ß\")\n",
    "data[\"text\"] = data[\"text\"].str.replace(\"Ã©\",\"é\")\n",
    "\n",
    "data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_csv(\"data.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# turn pandas df to huggingface dataset\n",
    "dataset = Dataset.from_pandas(data)\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split dataset into train and test set (80/20)\n",
    "ds = dataset.train_test_split(test_size=0.3)\n",
    "ds_test = ds[\"test\"]\n",
    "ds_train = ds[\"train\"]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds.push_to_hub(\"fathyshalab/reklambox-1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import set_seed\n",
    "from datasets import load_dataset\n",
    "from sentence_transformers.losses import (\n",
    "    CosineSimilarityLoss,\n",
    "    ContrastiveLoss,\n",
    "    BatchAllTripletLoss,\n",
    "    BatchHardTripletLoss,\n",
    ")\n",
    "from setfit import SetFitModel, SetFitTrainer, DistillationSetFitTrainer, sample_dataset\n",
    "import os\n",
    "from sklearn.metrics import f1_score, roc_auc_score\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import balanced_accuracy_score, f1_score, accuracy_score, roc_auc_score\n",
    "import plotly.express as px\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = load_dataset(\"fathyshalab/reklambox\")\n",
    "ds_train = ds[\"train\"]\n",
    "ds_test = ds[\"test\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#add a feature called sentence_length\n",
    "ds_train = ds_train.map(lambda x: {\"sentence_length\": len(x[\"text\"].split())})\n",
    "ds_test =  ds_test.map(lambda x: {\"sentence_length\": len(x[\"text\"].split())})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the sentence length distribution per label in a box plot\n",
    "fig = px.box(ds_train, x=\"label_name\", y=\"sentence_length\", color=\"label_name\")\n",
    "fig.show()\n",
    "fig = px.box(ds_test, x=\"label_name\", y=\"sentence_length\", color=\"label_name\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#filter the dataset to have only samples that are less than 512 tokens\t\n",
    "ds_train = ds_train.filter(lambda x: len(x[\"text\"].split()) < 256)\n",
    "ds_test = ds_test.filter(lambda x: len(x[\"text\"].split()) < 256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_train\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(y_pred,y_true):\n",
    "    return {\n",
    "        \"f1\": f1_score(y_true, y_pred, average=\"macro\"),\n",
    "        \"balanced_accuracy\": balanced_accuracy_score(y_true, y_pred),\n",
    "        \"accuracy\": accuracy_score(y_true, y_pred),\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# turn into dataframe and plot the distribution of sentences add an option to see the top 10 sentences  and the labels\n",
    "df = ds_train.to_pandas()\n",
    "df[\"text\"].str.split().apply(len).hist(bins=100)\n",
    "#sort the rows by label\n",
    "df.sort_values(by=\"label\", inplace=True)\n",
    "# label distribution  between train and test\n",
    "fig = px.histogram(df, x=\"label_name\", color=\"label_name\", title=\"Label distribution in train set\")\n",
    "fig.show()\n",
    "\n",
    "# turn into dataframe and plot the distribution of sentences\n",
    "df = ds_test.to_pandas()\n",
    "df.sort_values(by=\"label\", inplace=True)\n",
    "\n",
    "df[\"text\"].str.split().apply(len).hist(bins=100)\n",
    "# label distribution  between train and test in a pie chart\n",
    "fig = px.histogram(df, x=\"label_name\", color=\"label_name\")\n",
    "fig.show()\n",
    "\n",
    "\n",
    "# add sentence length to the dataset\n",
    "ds_train = ds_train.map(lambda x: {\"sentence_length\": len(x[\"text\"].split())})\n",
    "ds_test = ds_test.map(lambda x: {\"sentence_length\": len(x[\"text\"].split())})\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the sentence length distribution per label in a box plot\n",
    "fig = px.box(ds_train, x=\"label_name\", y=\"sentence_length\", color=\"label_name\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.box(ds_test, x=\"label_name\", y=\"sentence_length\", color=\"label_name\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds[\"train\"] = ds_train\n",
    "ds[\"test\"] = ds_test\n",
    "ds.push_to_hub(\"fathyshalab/reklambox-filtered\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\"\n",
    "\n",
    "train_ds = sample_dataset(ds_train, label_column=\"label\", num_samples=8)\n",
    "test_ds = ds[\"test\"]\n",
    "# Load SetFit model from Hub\n",
    "model = model = SetFitModel.from_pretrained(\"sentence-transformers/all-roberta-large-v1\")\n",
    "# Create trainer\n",
    "trainer = SetFitTrainer(\n",
    "    model=model,\n",
    "    train_dataset=train_ds,\n",
    "    eval_dataset=test_ds,\n",
    "    loss_class= ContrastiveLoss,\n",
    "    metric=compute_metrics,\n",
    "    batch_size=16,\n",
    "    num_epochs=10,\n",
    "    use_amp=True,\n",
    "    warmup_proportion=0.0\n",
    "\n",
    ")\n",
    "trainer.train()\n",
    "metrics = trainer.evaluate()\n",
    "print(metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define our classifier as a pipeline of token counts + naive bayes model\n",
    "classifier = Pipeline([(\"vect\", CountVectorizer()), (\"clf\", MultinomialNB())])\n",
    "\n",
    "# fit the classifier\n",
    "classifier.fit(X=ds_train[\"text\"], y=ds_train[\"label\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute test accuracy\n",
    "classifier.score(\n",
    "    X=ds_test[\"text\"],\n",
    "    y=ds_test[\"label\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get predicted probabilities for all labels\n",
    "probabilities = classifier.predict_proba(ds_test[\"text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_labels = ds_train.to_pandas()[\"label_name\"].unique()\n",
    "\n",
    "unique_labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create records for the test set\n",
    "records = [\n",
    "    rg.TextClassificationRecord(\n",
    "        text=data[\"text\"],\n",
    "        prediction=list(zip(unique_labels, prediction)),\n",
    "        annotation=unique_labels[data[\"label\"]],\n",
    "        metadata={\"split\": \"test\"},\n",
    "    )\n",
    "    for data, prediction in zip(ds_train, probabilities)\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get records with potential label errors\n",
    "records_with_label_error = find_label_errors(records)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# uncover label errors in the Argilla web app\n",
    "rg.log(records_with_label_error, \"label_errors\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# function to compute the loss example-wise\n",
    "def loss_per_example(batch):\n",
    "    encoded_input = tokenizer(batch[\"text\"], padding=True, truncation=True, return_tensors='pt',max_length=512).to(device)\n",
    "    labels = torch.tensor(batch[\"label\"], device=device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        output = model(**encoded_input)\n",
    "        batch[\"predicted_label\"] = torch.argmax(output.logits, axis=1)\n",
    "        # compute the probabilities for logging them into Argilla\n",
    "        batch[\"predicted_probas\"] = torch.nn.functional.softmax(output.logits, dim=0)\n",
    "\n",
    "    # don't reduce the loss (return the loss for each example)\n",
    "    loss = torch.nn.functional.cross_entropy(output.logits, labels, reduction=\"none\")\n",
    "    batch[\"loss\"] = loss\n",
    "\n",
    "    # datasets complains with numpy dtypes, let's use Python lists\n",
    "    for k, v in batch.items():\n",
    "\n",
    "        batch[k] = v\n",
    "\n",
    "    return batch\n",
    "losses_ds = ds_enc.map(\n",
    "    loss_per_example, batched=True, batch_size=32\n",
    ")\n",
    "\n",
    "# turn the dataset into a Pandas dataframe, sort by descending loss and visualize the top examples.\n",
    "pd.set_option(\"display.max_colwidth\", None)\n",
    "\n",
    "losses_ds.set_format(\"pandas\")\n",
    "losses_df = losses_ds[:][[\"label\", \"predicted_label\", \"loss\", \"predicted_probas\"]]\n",
    "\n",
    "# add the text column removed by the trainer\n",
    "losses_df[\"text\"] = ds_enc[\"text\"]\n",
    "losses_df.sort_values(\"loss\", ascending=False).head(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "ds = load_dataset(\"fathyshalab/mdsci\", split=\"test\")  # only for getting the label names\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_names = ds.to_pandas()[\"label_name\"].unique()\n",
    "label_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creates a Text classification record for logging into Argilla\n",
    "def make_record(row):\n",
    "    return rg.TextClassificationRecord(\n",
    "        text=row.text,\n",
    "        # this is the \"gold\" label in the original dataset\n",
    "        annotation=[(unique_labels[row.label])],\n",
    "        # this is the prediction together with its probability\n",
    "        prediction=[\n",
    "            (\n",
    "               unique_labels[row.predicted_label],\n",
    "                row.predicted_probas[row.predicted_label],\n",
    "            )\n",
    "        ],\n",
    "        # metadata fields can be used for sorting and filtering, here we log the loss\n",
    "        metadata={\"loss\": row.loss},\n",
    "        # who makes the prediction\n",
    "        prediction_agent=\"fathyshalab/autotrain-reklambox-3527295358\",\n",
    "        # source of the gold label\n",
    "        annotation_agent=\"fathyshalab/reklambox\",\n",
    "    )\n",
    "\n",
    "# if you want to log the full dataset remove the indexing\n",
    "top_losses = losses_df.sort_values(\"loss\", ascending=False)[0:499]\n",
    "\n",
    "# build Argilla records\n",
    "records = top_losses.apply(make_record, axis=1)\n",
    "\n",
    "rg.log(records, name=\"reklambox_error_analysis\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = rg.load(\"mdcsi\", query=\"annotated_by:argilla\").to_pandas()\n",
    "\n",
    "# let's do some transformations before uploading the dataset\n",
    "dataset[\"loss\"] = dataset.metadata.transform(lambda r: r[\"loss\"])\n",
    "dataset = dataset.rename(columns={\"annotation\": \"corrected_label\"})\n",
    "\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's add the original dataset labels to share them together with the corrected ones\n",
    "# we sort by ascending loss our corrected dataset\n",
    "dataset = dataset.sort_values(\"loss\", ascending=False)\n",
    "\n",
    "# we add original labels in string form\n",
    "id2label = list(dataset.corrected_label.unique())\n",
    "original_labels = [id2label[i] for i in top_losses[0:50].label.values]\n",
    "dataset[\"original_label\"] = original_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = dataset[[\"text\", \"corrected_label\", \"original_label\"]].to_dict(orient=\"list\")\n",
    "\n",
    "hf_ds = Dataset.from_dict(\n",
    "    ds,\n",
    "    features=Features(\n",
    "        {\n",
    "            \"text\": Value(\"string\"),\n",
    "            \"corrected_label\": ClassLabel(names=list(dataset.corrected_label.unique())),\n",
    "            \"original_label\": ClassLabel(names=list(dataset.corrected_label.unique())),\n",
    "        }\n",
    "    ),\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sensitive",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "831bf4e141bfe54aa3b3c0413f267c6e63869f4772dc00575936a2f190623634"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
