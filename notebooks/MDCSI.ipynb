{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import pandas as pd\n",
    "\n",
    "# Load the dataset\n",
    "dataset = load_dataset(\"fathyshalab/mdsci\",use_auth_token=True)\n",
    "\n",
    "dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Get the number of words in each text\n",
    "dataset[\"train\"] = dataset[\"train\"].map(lambda example: {\"text\": example[\"text\"], \"label\": example[\"label\"],\"domain\":example[\"domain\"], \"num_words\": len(example[\"text\"].split())})\n",
    "dataset[\"test\"] = dataset[\"test\"].map(lambda example: {\"text\": example[\"text\"], \"label\": example[\"label\"],\"domain\":example[\"domain\"], \"num_words\": len(example[\"text\"].split())})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.DataFrame(dataset[\"train\"])\n",
    "test_df = pd.DataFrame(dataset[\"test\"])\n",
    "train_df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stats about the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import pandas as pd\n",
    "\n",
    "# Create an empty dataframe to store the results\n",
    "latex_table = pd.DataFrame(columns=['Domain', 'Intent', 'Sample'])\n",
    "\n",
    "# Iterate over unique domains in the train_df dataframe\n",
    "for domain in train_df['domain'].unique():\n",
    "    # Iterate over unique intents within each domain\n",
    "    for intent in train_df[train_df['domain'] == domain]['label_name'].unique():\n",
    "        # Get the first sample for the current domain and intent\n",
    "        sample = train_df[(train_df['domain'] == domain) & (train_df['label_name'] == intent)]['text'].iloc[0]\n",
    "        # Replace line breaks with LaTeX line break command\n",
    "        # Append the domain, intent, and sample to the latex_table dataframe\n",
    "        latex_table = latex_table.append({'Domain': domain, 'Intent': intent, 'Sample': sample}, ignore_index=True)\n",
    "\n",
    "# Convert the dataframe to LaTeX format\n",
    "\n",
    "df =latex_table\n",
    "# Select the first row per domain\n",
    "smaller_df = df.groupby('Domain').first().reset_index()\n",
    "with open(\"my_table_small.tex\", \"w\") as f:\n",
    "    f.write(\"\\\\begin{tabular}{\" + \" | \".join([\"c\"] * len(smaller_df.columns)) + \"}\\n\")\n",
    "    for i, row in smaller_df.iterrows():\n",
    "        f.write(\" & \".join([str(x) for x in row.values]) + \" \\\\\\\\\\n\")\n",
    "    f.write(\"\\\\end{tabular}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(latex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "latex_table[\"Sample\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe = train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.histogram(dataframe, x='domain', template='plotly_white', title='Queries counts by Domain')\n",
    "fig.update_xaxes(categoryorder='total descending').update_yaxes(title='DOMAIN')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.histogram(dataframe, x='label_name', template='plotly_white', title='Queries counts by Intent')\n",
    "fig.update_xaxes(categoryorder='total descending').update_yaxes(title='INTENT')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.histogram(dataframe, x='num_words', template='plotly_white', title='Queries counts by word count')\n",
    "fig.update_xaxes(categoryorder='total descending').update_yaxes(title='Number of Queries')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Complaints by company & date\n",
    "fig = px.histogram(dataframe, x='label_name', template='plotly_white', title='Queries counts by intent'\n",
    "                   , color='domain')\n",
    "fig.update_xaxes(categoryorder='category descending', title='Intent').update_xaxes(title='Number of queries')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.treemap(dataframe, title='Treemap chart by domain and the corresponding intent with the average n_words',\n",
    "                 path=['domain', 'label_name'], color='num_words', color_continuous_scale=px.colors.sequential.GnBu, width=2048)\n",
    "fig.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Qualitative comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords as nltk_stopwords\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def perform_tfidf_analysis(texts, intent):\n",
    "    \"\"\"\n",
    "    Performs TF-IDF analysis on a list of texts.\n",
    "\n",
    "    Args:\n",
    "    - texts (list): List of strings containing the texts\n",
    "\n",
    "    Returns:\n",
    "    - None\n",
    "    \"\"\"\n",
    "    # Remove German stopwords from texts\n",
    "    stopwords = nltk_stopwords.words('german')\n",
    "    texts = [' '.join([word for word in text.split() if word.lower() not in stopwords]) for text in texts]\n",
    "\n",
    "    # Vectorize the texts using TF-IDF\n",
    "    tfidf = TfidfVectorizer()\n",
    "    tfidf_matrix = tfidf.fit_transform(texts)\n",
    "\n",
    "    # Compute document similarities\n",
    "    similarity_matrix = cosine_similarity(tfidf_matrix)\n",
    "\n",
    "    # Identify common and rare words\n",
    "    word_scores = pd.DataFrame(tfidf_matrix.sum(axis=0), columns=tfidf.get_feature_names_out()).T\n",
    "    word_scores.columns = ['tfidf_score']\n",
    "    word_scores = word_scores.sort_values('tfidf_score', ascending=False)\n",
    "\n",
    "    # Visualize the results\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(12, 6))\n",
    "\n",
    "    # Scatter plot of similarity scores\n",
    "    similarity_matrix = [i for i in similarity_matrix if i[1] < 0.99]\n",
    "    sns.scatterplot(x=[i[0] for i in similarity_matrix], y=[i[1] for i in similarity_matrix], ax=axes[0])\n",
    "    axes[0].set_xlabel('Sample Index')\n",
    "    axes[0].set_ylabel('Similarity Score')\n",
    "    axes[0].set_title('Similarity Scores between Samples')\n",
    "\n",
    "    # Bar plot of top 20 words by TF-IDF score\n",
    "    sns.barplot(x=word_scores.head(20).tfidf_score, y=word_scores.head(20).index, ax=axes[1])\n",
    "    axes[1].set_xticklabels(axes[1].get_xticklabels(), rotation=90)\n",
    "    axes[1].set_xlabel('TF-IDF Score')\n",
    "    axes[1].set_ylabel('Word')\n",
    "    axes[1].set_title('Top 20 Words by TF-IDF Score')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f\"tfid-{intent}.png\")\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for intent in train_df['label_name'].unique():\n",
    "    texts = train_df[train_df['label_name'] == intent]['text'].tolist()\n",
    "    perform_tfidf_analysis(texts, intent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, balanced_accuracy_score, accuracy_score,f1_score\n",
    "from sentence_transformers import SentenceTransformer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def baseline(dmo,dataset):\n",
    "    \"\"\"Running the baseline which in this case is the embeeding and logistic regression steps combined\"\"\"\n",
    "    model_name = f\"fathyshalab/reklambox-{dmo}-setfit\"\n",
    "    embedding_model = SentenceTransformer(model_name, use_auth_token=True)\n",
    "    train_embeedings = embedding_model.encode(dataset[\"train\"][\"text\"])\n",
    "    test_embeedings = embedding_model.encode(dataset[\"test\"][\"text\"])\n",
    "    X = np.array(list(train_embeedings))\n",
    "    y = dataset[\"train\"][\"label\"]\n",
    "    y_test = dataset[\"test\"][\"label\"]\n",
    "    X_test = np.array(list(test_embeedings))\n",
    "\n",
    "    # Train a logistic regression model on the averaged embeddings\n",
    "    clf = LogisticRegression(random_state=42).fit(X, y)\n",
    "\n",
    "    # Make predictions on the test set\n",
    "    y_pred = clf.predict(X_test)\n",
    "\n",
    "    # Print the classification report\n",
    "    # print(classification_report(y_test, y_pred))\n",
    "    f1 =  f1_score(y_test, y_pred, average=\"weighted\")\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    balanced_accuracy = balanced_accuracy_score(y_test, y_pred)\n",
    "    return f1,accuracy,balanced_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dms = [\n",
    "    \"supermaerkte-drogerien\",\n",
    "    \"mode-schmuck-zubehoer\",\n",
    "    \"moebel-einrichtungshaeuser\",\n",
    "    \"finanzen\",\n",
    "    \"reisen-tourismus\",\n",
    "    \"schoenheit-wellness\",\n",
    "    \"unternehmen-verbaende\",\n",
    "    \"medizin-gesundheit-pflege\",\n",
    "    \"transport-logistik\",\n",
    "    \"versicherungen-recht\",\n",
    "    \"oeffentlichkeit-soziales\",\n",
    "    \"oeffentlicher-verkehr-vermietung\",\n",
    "    \"unterhaltung-kultur-freizeit\",\n",
    "    \"wasser-strom-gas\",\n",
    "    \"haus-reinigung\",\n",
    "]\n",
    "from tqdm import tqdm\n",
    "metricss ={dm:{} for dm in dms}\n",
    "for dm in tqdm(dms):\n",
    "    dataset = load_dataset(f\"fathyshalab/mdcsi_{dm}\", use_auth_token=True)\n",
    "    f,a,b = baseline(dm,dataset)\n",
    "    metricss[dm][\"f1\"]=f\n",
    "    metricss[dm][\"accuracy\"]=a\n",
    "    metricss[dm][\"balanced_accuracy\"]=b\n",
    "\n",
    "\n",
    "metricss\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# take metricss and plot them\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "df = pd.DataFrame(metricss).T\n",
    "df = df.reset_index()\n",
    "df = df.rename(columns={\"index\":\"domain\"})\n",
    "df = df.melt(id_vars=[\"domain\"],  var_name=\"metric\", value_name=\"value\")\n",
    "df[\"metric\"] = df[\"metric\"].str.replace(\"_\",\" \")\n",
    "df[\"metric\"] = df[\"metric\"].str.title()\n",
    "df[\"metric\"] = df[\"metric\"].str.replace(\"F1\",\"F1-Score\")\n",
    "df[\"metric\"] = df[\"metric\"].str.replace(\"Accuracy\",\"Accuracy-Score\")\n",
    "df[\"metric\"] = df[\"metric\"].str.replace(\"Balanced Accuracy\",\"Balanced Accuracy-Score\")\n",
    "df[\"metric\"] = df[\"metric\"].str.replace(\" \",\"\\n\")\n",
    "df[\"metric\"] = df[\"metric\"].str.replace(\"-\",\"- \")\n",
    "# plot\n",
    "sns.set_theme(style=\"whitegrid\")\n",
    "plt.figure(figsize=(20, 10))\n",
    "ax = sns.barplot(x=\"value\", y=\"domain\", hue=\"metric\", data=df)\n",
    "ax.set_xticklabels(ax.get_xticklabels())\n",
    "plt.savefig(\"baseline.png\")\n",
    "plt.legend(loc='lower right')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import altair as alt\n",
    "from matplotlib import pyplot as plt\n",
    "import pandas as pd\n",
    "with open(\"setfit-soupres5-new.json\",\"r\") as f :\n",
    "    data = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for d in data.keys():\n",
    "    for md in metricss.keys():\n",
    "        if d==md:\n",
    "            data[d][\"orig\"]=metricss[md]\n",
    "\n",
    "data['supermaerkte-drogerien']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alt.data_transformers.disable_max_rows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "table_rows = []\n",
    "metrics = ['f1', 'accuracy', 'balanced_accuracy']\n",
    "\n",
    "# Iterate over the data\n",
    "for domain_name, domain_data in data.items():\n",
    "\n",
    "    for metric in metrics:\n",
    "        # Find the metric with the highest value for that metric that is not the baseline but contains the domain name\n",
    "        max_metric = max(domain_data, key=lambda x: domain_data[x][metric] if x != 'orig' and domain_name in x else 0)\n",
    "        # Get the value of the metric\n",
    "        value = domain_data[max_metric][metric]\n",
    "        baseline_value = domain_data['orig'][metric]\n",
    "\n",
    "        # Determine the improvement, decrease, or no change\n",
    "        if value > baseline_value:\n",
    "            improvement = 'Improvement'\n",
    "        elif value < baseline_value:\n",
    "            improvement = 'Decrease'\n",
    "        else:\n",
    "            improvement = 'No Change'\n",
    "\n",
    "        percent_diff = (value - baseline_value) / baseline_value * 100\n",
    "        # Add the row to the table\n",
    "        table_rows.append([domain_name, metric, value,baseline_value,max_metric,improvement,percent_diff])\n",
    "\n",
    "# Create a pandas DataFrame with the table rows\n",
    "df = pd.DataFrame(table_rows, columns=['Domain', 'Metric', ' SETFIT Value',\"Baseline Value\",\"Combo Name\",'Change','% Difference'],index=None)\n",
    "# export the table for powerpoint\n",
    "df.to_csv(\"setfit-soupres5new.csv\",index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_latex(\"setfit-soupres5new.tex\",index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#make smaller df where i just have the domain and say if there was an improvement or not\n",
    "df2 = df[[\"Domain\",\"Change\"]]\n",
    "df2 = df2.groupby([\"Domain\",\"Change\"])\n",
    "df2 = df2.size().reset_index(name='counts')\n",
    "df2.to_latex(\"setfit-soupres5new-small.tex\",index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the data to a tidy dataframe\n",
    "df = pd.DataFrame([(category, subcategory, metric, scores[metric])\n",
    "                   for category, subcategories in data.items()\n",
    "                   for subcategory, scores in subcategories.items()\n",
    "                   for metric in scores.keys()],\n",
    "                  columns=['Category', 'Subcategory', 'Metric', 'Value'])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_latex(\"setfit-soupres5new.tex\",index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Convert the data to a tidy dataframe\n",
    "df = pd.DataFrame([(category, subcategory, metric, scores[metric])\n",
    "                   for category, subcategories in data.items()\n",
    "                   for subcategory, scores in subcategories.items()\n",
    "                   for metric in scores.keys()],\n",
    "                  columns=['Category', 'Subcategory', 'Metric', 'Value'])\n",
    "\n",
    "# Create a dropdown selection for the category\n",
    "category_selection = alt.selection_single(\n",
    "    name='CategorySelector',\n",
    "    fields=['Category'],\n",
    "    bind=alt.binding_select(options=list(data.keys())),\n",
    "    init={'Category': list(data.keys())[0]}\n",
    ")\n",
    "\n",
    "# Create a list to store the bar plots\n",
    "bar_plots = []\n",
    "\n",
    "# Iterate over each domain\n",
    "for domain, domain_data in data.items():\n",
    "    # Create a subset of the data for the current domain\n",
    "    domain_df = df[df['Category'] == domain]\n",
    "    \n",
    "    # Create a separate bar plot for each metric in the current domain\n",
    "    for metric in domain_data['orig'].keys():\n",
    "        # Filter the data for the current metric\n",
    "        metric_data = domain_df[domain_df['Metric'] == metric]\n",
    "        \n",
    "        # Select the top 10 values for the current metric within the domain\n",
    "        top_10_data = metric_data.nlargest(10, 'Value')\n",
    "        \n",
    "        # Create a bar plot for the current metric within the domain\n",
    "        plt.figure(figsize=(6, 4))\n",
    "        sns.barplot(data=top_10_data, x='Value', y='Subcategory', hue='Category',\n",
    "                    dodge=False)\n",
    "        plt.title(f\"{metric} - {domain}\")\n",
    "        plt.xlabel(metric)\n",
    "        plt.ylabel(\"Subcategory\")\n",
    "        plt.tight_layout()\n",
    "        \n",
    "        # Add the bar plot to the list\n",
    "        bar_plots.append(plt)\n",
    "\n",
    "# Show the bar plots for each domain\n",
    "for bar_plot in bar_plots:\n",
    "    bar_plot.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sensitive",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
